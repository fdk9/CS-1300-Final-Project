{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import re\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class ReziewAlgorithm:\n",
    "\n",
    "    data = None\n",
    "    reviews_ratings = None\n",
    "    all_reviews = None\n",
    "    review_train = None\n",
    "    review_test = None\n",
    "    rating_train = None\n",
    "    rating_test = None\n",
    "\n",
    "    vec_review_train = None\n",
    "    vec_review_test = None\n",
    "\n",
    "    stop_words = ['a', 'the', 'that', 'of', 'which', 'i', 'it', 'this', 'too', 'sometime', 'sometimes', 'slightly', 'somewhat']\n",
    "    cv = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "\n",
    "    max_c = None\n",
    "    final_model = None\n",
    "\n",
    "    sorted_words = None\n",
    "    word_score_dict = {}\n",
    "    word_counts = {}\n",
    "\n",
    "    # read in the .csv file and drops all rows without a valid review or rating\n",
    "    def read_csv(self, file, review_col, rating_col):\n",
    "        data = pd.read_csv(file)\n",
    "        data.drop(data[data['lang'] != 'en'].index, inplace=True)\n",
    "        data[rating_col].replace(r\"\\D\", \"\", inplace=True, regex = True)\n",
    "        data[rating_col].replace(\"\", np.nan, inplace=True)\n",
    "        data[review_col].replace(\"\", np.nan, inplace=True)\n",
    "        data.dropna(subset=[rating_col], inplace=True)\n",
    "        data.dropna(subset=[review_col], inplace=True)\n",
    "        self.data = data\n",
    "\n",
    "    def __init__(self, file, review_col, rating_col):\n",
    "        self.read_csv(file, review_col, rating_col)\n",
    "\n",
    "    # store the review and rating columns as a class variable\n",
    "    def extract_cols(self):\n",
    "        reviews = pd.DataFrame()\n",
    "        reviews['reviews'] = self.data['review_text']\n",
    "        reviews['ratings'] = self.data['grade']\n",
    "        self.reviews_ratings = reviews\n",
    "\n",
    "    # convert ratings to binary scale and split into train and test subset \n",
    "    def preprocess_ratings(self):\n",
    "        ratings = self.reviews_ratings['ratings']\n",
    "        n = int(len(ratings) * (2/3))\n",
    "        rating_list = ratings.tolist()\n",
    "        def convert_rating(x):\n",
    "            x = int(x)\n",
    "            if x < 4:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        rating_list = [convert_rating(x) for x in rating_list]\n",
    "        rating_train = rating_list[0:n]\n",
    "        rating_test = rating_list[n:]\n",
    "        self.rating_train = rating_train\n",
    "        self.rating_test = rating_test\n",
    "\n",
    "    # remove punctuation from reviews and split into train and test subset\n",
    "    def preprocess_reviews(self):\n",
    "        reviews = self.reviews_ratings['reviews']\n",
    "        n = int(len(reviews) * (2/3))\n",
    "        review_list = reviews.tolist()\n",
    "        REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "        REPLACE_WITH_SPACE = re.compile(\"(\\-)|(\\/)\")\n",
    "        processed_reviews = [REPLACE_NO_SPACE.sub(\"\", str(line).lower()) for line in review_list]\n",
    "        processed_reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in review_list]\n",
    "        reviews_train = processed_reviews[0:n]\n",
    "        reviews_test = processed_reviews[n:]\n",
    "        self.all_reviews = processed_reviews\n",
    "        self.review_train = reviews_train\n",
    "        self.review_test = reviews_test\n",
    "\n",
    "    # transform reviews into vector input for regression model\n",
    "    def vectorize_reviews(self):\n",
    "        self.cv.fit(self.review_train)\n",
    "        self.vec_review_train = self.cv.transform(self.review_train)\n",
    "        self.vec_review_test = self.cv.transform(self.review_test)\n",
    "\n",
    "    # train logistic regression model on different parameters and returns parameter with highest accuracy\n",
    "    def train_model_for_c(self):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            self.vec_review_train, self.rating_train, train_size = 0.75\n",
    "        )\n",
    "\n",
    "        c_list = np.linspace(1, 1.3, num=3)\n",
    "        c_accuracy = {}\n",
    "        for c in c_list:\n",
    "            lr = LogisticRegression(C=c)\n",
    "            lr.fit(X_train, y_train)\n",
    "            c_accuracy[c] = accuracy_score(y_val, lr.predict(X_val))\n",
    "            print(\"Accuracy for C=%s: %s\" \n",
    "                % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "        self.max_c = max(c_accuracy.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "    # fit a model using the optimal parameter\n",
    "    def get_final_model(self):\n",
    "        final_model = LogisticRegression(C=self.max_c)\n",
    "        self.final_model = final_model.fit(self.vec_review_train, self.rating_train)\n",
    "\n",
    "    # test optimal model on test data subset and print accuracy\n",
    "    def test_model(self):\n",
    "        print (\"Final Accuracy: %s\" \n",
    "            % accuracy_score(self.rating_test, self.final_model.predict(self.vec_review_test)))\n",
    "\n",
    "    # store dictionary of words and sentiment scores as class variable\n",
    "    def get_words_and_scores(self):\n",
    "        feature_to_coef = {\n",
    "            word: coef for word, coef in zip(\n",
    "                self.cv.get_feature_names(), self.final_model.coef_[0]\n",
    "            )\n",
    "        }\n",
    "\n",
    "        self.sorted_words = sorted(feature_to_coef.items(), key=lambda x: x[1])\n",
    "        self.word_score_dict = dict(self.sorted_words)\n",
    "\n",
    "    def get_most_positive_negative_words(self):\n",
    "        num_words = 10\n",
    "        word_dict = {'positive': {'words': [], 'weights': [], 'reviews': [], 'hits': []},\n",
    "                    'negative': {'words': [], 'weights': [], 'reviews': [], 'hits': []}}\n",
    "\n",
    "\n",
    "        for best_positive in reversed(self.sorted_words[-num_words:]):\n",
    "            positive_dict = word_dict['positive']\n",
    "            positive_dict['words'].append(best_positive[0])\n",
    "            positive_dict['weights'].append(best_positive[1])\n",
    "            print (best_positive)\n",
    "            \n",
    "        for best_negative in self.sorted_words[:num_words]:\n",
    "            negative_dict = word_dict['negative']\n",
    "            negative_dict['words'].append(best_negative[0])\n",
    "            negative_dict['weights'].append(best_negative[1])\n",
    "            print (best_negative)\n",
    "\n",
    "    # return sentiment score of a given word, or None if that word does not exist in the corpus\n",
    "    def get_sentiment_score(self, word):\n",
    "        word = word.strip().lower()\n",
    "        if word in self.word_score_dict:\n",
    "            return self.word_score_dict[word]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    # return the number of reviews in which a given word appears\n",
    "    def get_review_count(self, word):\n",
    "        if word in self.word_counts:\n",
    "            return self.word_counts[word]\n",
    "        hit_list = [idx for idx, s in enumerate(self.all_reviews) if word in s]\n",
    "        self.word_counts[word] = len(hit_list)\n",
    "        return self.word_counts[word]\n",
    "        \n",
    "    # helper function for analyze(). finds all of the adjs associated with a noun\n",
    "    def recurse(self, adj):\n",
    "        word = adj.text\n",
    "        if self.get_sentiment_score(word) == None or self.get_review_count(word) == 0:\n",
    "            return []\n",
    "        out = [(word, self.get_sentiment_score(word), self.get_review_count(word))]\n",
    "        for child in adj.children:\n",
    "            if child.pos_ == \"ADJ\":\n",
    "                out += self.recurse(child)\n",
    "        return out\n",
    "\n",
    "    # reutrn a dictionary of nouns and the adjectives that are associated with them\n",
    "    def analyze(self, s):\n",
    "        s = s.lower()\n",
    "        doc = nlp(s)\n",
    "        pairs = {}\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"AUX\":\n",
    "                n = \"\"\n",
    "                a = []\n",
    "                for child in token.children:\n",
    "                    if child.pos_ == \"NOUN\" and len(child.text) > 2:\n",
    "                        n = child.text\n",
    "                    elif child.pos_ == \"ADJ\":\n",
    "                        a += self.recurse(child)\n",
    "                if n != \"\" and a != []:\n",
    "                    if n in pairs:\n",
    "                        pairs[n] = sorted(set(pairs[n] + a))\n",
    "                    else:\n",
    "                        pairs[n] = sorted(set(a))\n",
    "            if token.pos_ == \"NOUN\" and len(token.text) > 2:\n",
    "                a = []\n",
    "                for child in token.children:\n",
    "                    if child.pos_ == \"ADJ\":\n",
    "                        a += self.recurse(child) # Recurse might not be neccesary\n",
    "                if a != []:\n",
    "                    if token.text in pairs:\n",
    "                        pairs[token.text] = sorted(set(pairs[token.text] + a))\n",
    "                    else:\n",
    "                        pairs[token.text] = sorted(set(a))\n",
    "        return pairs\n",
    "    \n",
    "    # shortcut function for training model on dataset\n",
    "    def train_model(self):\n",
    "        self.extract_cols()\n",
    "        self.preprocess_ratings()\n",
    "        self.preprocess_reviews()\n",
    "        self.vectorize_reviews()\n",
    "        self.train_model_for_c()\n",
    "        self.get_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReziewAlgorithm('reziew.csv', 'review_text', 'grade')\n",
    "model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reviews_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.max_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_model()\n",
    "model.get_words_and_scores()\n",
    "model.get_most_positive_negative_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_review = ''\n",
    "revs = model.all_reviews\n",
    "for i in range(0, len(revs)):\n",
    "    if len(long_review) < 999000:\n",
    "        try:\n",
    "            long_review += (revs[i] + '. ')\n",
    "        except:\n",
    "            pass\n",
    "#rev = reviews['reviews'][4]\n",
    "#print(long_review)\n",
    "result = model.analyze(long_review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_list = []\n",
    "for k, v in result.items():\n",
    "    ct = model.get_review_count(k)\n",
    "    if (ct > 0):\n",
    "        new_dict = {}\n",
    "        new_dict['noun'] = k\n",
    "        new_dict['noun_count'] = ct\n",
    "        new_dict['adjs'] = [tup[0] for tup in v]\n",
    "        new_dict['adjs_score'] = [tup[1] for tup in v]\n",
    "        new_dict['adjs_count'] = [tup[2] for tup in v]\n",
    "        new_dict['noun_score'] = (np.sum(np.multiply(new_dict['adjs_score'], new_dict['adjs_count'])))/np.sum(new_dict['adjs_count'])\n",
    "        json_list.append(new_dict)\n",
    "    \n",
    "def get_noun_count(json):\n",
    "    try:\n",
    "        return int(json['noun_count'])\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "def get_noun_score(json):\n",
    "    try:\n",
    "        return int(json['noun_score'])\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "json_list.sort(key=get_noun_score, reverse=True)\n",
    "json_output = json.dumps(json_list)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.word_score_dict)\n",
    "\n",
    "# LEFTOVER CODE FOR GETTING REVIEW IN WHICH A WORD APPEARS\n",
    "# for word in word_dict['positive']['words']:\n",
    "#     hit_list = [idx for idx, s in enumerate(reviews_clean) if word in s]\n",
    "#     first_hit = hit_list[0]\n",
    "#     word_dict['positive']['reviews'].append(review_list[first_hit])\n",
    "#     word_dict['positive']['hits'].append(len(hit_list))\n",
    "#     print(review_list[first_hit])\n",
    "#     print(len(hit_list))\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# for word in word_dict['negative']['words']:\n",
    "#     hit_list = [idx for idx, s in enumerate(reviews_clean) if word in s]\n",
    "#     first_hit = hit_list[0]\n",
    "#     word_dict['negative']['reviews'].append(review_list[first_hit])\n",
    "#     word_dict['negative']['hits'].append(len(hit_list))\n",
    "#     print(review_list[first_hit])\n",
    "#     print(len(hit_list))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
